
import { Flashcard } from '@/types';

// Fonction pour générer un ID unique
const generateId = () => {
  return Math.random().toString(36).substring(2, 15) + Math.random().toString(36).substring(2, 15);
};

export const readingAvanceIELTSFlashcards: Flashcard[] = [
  {
    id: generateId(),
    question: "According to the passage, which philosophical perspective on consciousness has gained the most empirical support from recent neuroscientific research?",
    answer: "Non-reductive physicalism",
    matiere: "IELTS Reading",
    niveau: "avance",
    diplome: "ielts",
    text: "Consciousness remains neuroscience's most profound theoretical challenge, with competing philosophical frameworks offering distinct conceptualizations of the mind-brain relationship. Cartesian dualism, positing mind and brain as fundamentally different substances, has largely receded in scientific discourse given mounting evidence of consciousness's dependence on neural activity. However, the precise nature of this dependence continues to generate debate. Reductive physicalism, which claims conscious experiences are entirely reducible to neural processes, struggles to explain the explanatory gap between objective descriptions of brain states and subjective phenomenal experiences—the \"what it is like\" quality of consciousness. Non-reductive physicalism addresses this limitation by acknowledging consciousness as physically instantiated while maintaining that phenomenal properties emerge from neural complexity in ways not reducible to simpler physical components. This perspective has garnered substantial empirical support from studies demonstrating that conscious experiences correlate with distributed neural networks rather than discrete brain regions, suggesting emergent properties not evident at smaller scales of analysis. Integrated information theory further formalizes this relationship by quantifying consciousness through mathematical measures of information integration across neural systems. Alternative perspectives including panpsychism—the view that consciousness exists as a fundamental property throughout the universe—have experienced renewed philosophical interest but remain empirically challenging to investigate. Recent methodological developments, including no-report paradigms that distinguish consciousness from metacognition and report, have enabled more precise investigations of neural correlates of consciousness while controlling for confounding cognitive processes. Despite significant advances in identifying specific neural signatures associated with conscious experiences, a comprehensive theory explaining how and why physical processes generate subjective experience—the \"hard problem\" of consciousness—remains elusive, suggesting potential fundamental limitations in our conceptual frameworks for understanding consciousness through conventional scientific approaches."
  },
  {
    id: generateId(),
    question: "What does the author identify as the most significant limitation of contemporary climate models in predicting regional climate changes?",
    answer: "Their inability to accurately represent cloud feedback mechanisms at regional scales",
    matiere: "IELTS Reading",
    niveau: "avance",
    diplome: "ielts",
    text: "Climate modeling has evolved substantially since the first general circulation models emerged in the 1960s, with contemporary Earth System Models incorporating increasingly sophisticated representations of atmospheric physics, oceanic circulation, cryospheric processes, and biogeochemical cycles. These models demonstrate remarkable skill in reproducing observed global temperature trends and projecting planetary-scale responses to anthropogenic forcing. However, significant limitations persist in simulating regional climate changes, particularly regarding precipitation patterns and extreme weather events. Perhaps the most consequential limitation involves cloud feedback mechanisms, which remain the largest source of uncertainty in climate sensitivity estimates. While models generally agree that cloud feedbacks are likely positive (amplifying warming) globally, regional cloud responses vary substantially across models, creating significant divergence in localized climate projections. This uncertainty stems from the inherent scale mismatch between model resolution (typically tens of kilometers) and the microphysical processes governing cloud formation and evolution (occurring at meters or smaller). Parameterization schemes attempting to bridge this scale gap necessarily simplify complex processes, introducing systematic biases that propagate through model projections. Additionally, current models inadequately represent certain modes of climate variability, including the El Niño-Southern Oscillation and the Madden-Julian Oscillation, which significantly influence regional climate patterns. Land-atmosphere coupling, particularly involving soil moisture feedbacks and vegetation dynamics, represents another area where model disagreement generates substantial uncertainty in regional projections, especially for mid-latitude agricultural regions. While ensemble approaches and constraint methodologies have improved projection reliability, fundamental structural uncertainties persist. Nevertheless, these limitations should not undermine confidence in the robust, physically-grounded conclusions regarding global warming trajectories; rather, they highlight specific research priorities for improving decision-relevant regional climate information. The next generation of climate models, incorporating variable-resolution grids, improved parameterization schemes, and more comprehensive Earth system processes, promises to address some current limitations, though computational constraints continue to necessitate trade-offs between resolution, complexity, and ensemble size."
  },
  {
    id: generateId(),
    question: "According to the passage, what fundamental misconception has hampered traditional approaches to artificial general intelligence?",
    answer: "The assumption that human-like reasoning emerges primarily from rule-based logical operations rather than embodied experience",
    matiere: "IELTS Reading",
    niveau: "avance",
    diplome: "ielts",
    text: "Artificial General Intelligence (AGI)—the hypothesized capacity of computational systems to perform intellectual tasks comparable to or exceeding human abilities across diverse domains—has remained elusive despite remarkable advances in narrow AI applications. This persistent gap between aspiration and achievement partially stems from fundamental misconceptions about the nature of human cognition that have historically guided AGI research. Traditional approaches, originating from symbolic AI paradigms, implicitly assumed that human-like reasoning emerges primarily from rule-based logical operations implemented through formal symbol manipulation. This conception, however, increasingly contradicts evidence from cognitive science and developmental psychology suggesting that human intelligence fundamentally derives from embodied experience within physical and social environments. Our cognitive capacities do not develop as abstract reasoning modules but rather emerge through sensorimotor interaction with the world, social learning processes, and the gradual accumulation of contextual knowledge that forms the tacit foundation for seemingly abstract reasoning. Contemporary neuroscience further challenges computational metaphors of mind by revealing that neural processing bears little resemblance to serial computational architecture, instead operating through massively parallel, probabilistic mechanisms that continuously integrate bottom-up sensory information with top-down predictive models. The apparent modularity of cognitive functions reflects functional organization rather than genuinely independent processing systems. Recent advances in deep learning architectures, particularly transformer models, have demonstrated unprecedented capabilities in language processing and multimodal learning, suggesting alternative pathways toward artificial general intelligence. However, these systems fundamentally differ from human cognition in their developmental trajectory, lacking embodied experience, intrinsic motivation, and the social scaffolding that shapes human learning. While they excel at pattern recognition within their training distribution, they struggle with causal reasoning, counterfactual thinking, and adapting knowledge to novel contexts—precisely the flexible cognition that characterizes general intelligence. Promising research directions addressing these limitations include developmental robotics approaches that emphasize embodied learning, systems incorporating intrinsic motivation and curiosity-driven exploration, and architectures integrating both symbolic and subsymbolic processing to combine the strengths of logical reasoning with statistical learning. Nevertheless, the field increasingly recognizes that artificial general intelligence may not necessarily recapitulate human cognitive architecture, potentially achieving similar functional capabilities through fundamentally different computational principles—raising profound questions about how we evaluate and compare different forms of intelligence."
  },
  {
    id: generateId(),
    question: "Based on the passage, what is the most significant ethical challenge associated with human genetic enhancement technologies?",
    answer: "Determining whether genetic interventions that substantially exceed normal human capabilities should be permitted when they create categorical advantages",
    matiere: "IELTS Reading",
    niveau: "avance",
    diplome: "ielts",
    text: "Emerging genetic enhancement technologies, particularly CRISPR-Cas9 and related gene editing systems, present unprecedented opportunities to modify human capabilities beyond therapeutic applications, raising profound ethical questions that existing bioethical frameworks struggle to adequately address. While traditional bioethical principles—autonomy, beneficence, non-maleficence, and justice—provide valuable guidance for therapeutic interventions, enhancement applications challenge fundamental assumptions about these principles' scope and application. Autonomy-based arguments supporting enhancement emphasize parental reproductive freedom and individual self-determination, yet these considerations necessarily confront tensions with intergenerational justice and the autonomy of future persons whose genetic constitutions are irrevocably determined without their consent. Concerns regarding distributive justice appear particularly acute given the likelihood that enhancement technologies would initially be accessible exclusively to privileged populations, potentially exacerbating existing socioeconomic disparities by transforming them into biological inequalities. However, categorical objections to enhancement based solely on distributive concerns encounter the \"leveling down\" problem—the counterintuitive implication that preventing enhancements that cannot be universally distributed deprives society of aggregate benefits that might indirectly advantage even non-enhanced individuals. Conservative perspectives emphasizing the wisdom embodied in natural selection face the challenge of distinguishing principled objections to enhancement from historical resistance to technological innovations that now constitute standard medical practice. Conversely, transhumanist positions advocating aggressive enhancement confront legitimate concerns about undermining fundamental aspects of human experience that emerge from our biological limitations. Perhaps most challenging are threshold questions regarding which genetic modifications constitute enhancements versus treatments—a distinction complicated by the context-dependent nature of traits like height, memory capacity, or emotional resilience, which may benefit individuals in some environments while proving disadvantageous in others. More nuanced approaches recognize that enhancements exist on a spectrum rather than as binary categories, with interventions addressing clear biological dysfunction relatively uncontroversial, while those substantially exceeding species-typical functioning generate legitimate ethical concerns. Particularly contentious are potential cognitive enhancements that might create categorical advantages in competitive domains like academic achievement or economic productivity. Democratic governance frameworks incorporating diverse perspectives appear necessary for navigating these complex issues, though global consensus remains elusive given divergent cultural values regarding technological intervention in human development. Whatever regulatory approaches ultimately emerge will require sufficient flexibility to adapt to rapidly evolving technological capabilities while maintaining commitment to fundamental human dignity and equal moral consideration."
  },
  {
    id: generateId(),
    question: "According to the author, what represents the most significant epistemological challenge in evaluating indigenous knowledge systems alongside Western scientific frameworks?",
    answer: "Reconciling different criteria for validating knowledge while avoiding both uncritical relativism and epistemological imperialism",
    matiere: "IELTS Reading",
    niveau: "avance",
    diplome: "ielts",
    text: "Indigenous knowledge systems represent complex epistemological frameworks that have increasingly garnered attention from Western scientific communities, particularly regarding environmental management, biodiversity conservation, and climate adaptation strategies. The relationship between these knowledge traditions has historically been characterized by marginalization and appropriation of indigenous perspectives, reflecting broader colonial power dynamics rather than substantive epistemological engagement. Contemporary discourse often oscillates between uncritical relativism that romanticizes indigenous knowledge and dismissive scientism that delegitimizes non-Western epistemologies by applying inappropriate evaluative criteria. A more productive approach recognizes both the contextual validity of indigenous knowledge—developed through generations of place-based observation and practical engagement with local ecosystems—and the distinctive strengths of scientific methodology in systematically testing hypotheses across diverse contexts. Indigenous knowledge systems typically emphasize holistic understanding, relational thinking, and intergenerational transmission of ecological relationships embedded within cultural practices and linguistic structures. These systems often excel at detecting subtle environmental changes, understanding complex ecological interactions, and maintaining sustainable resource management practices adapted to local conditions. Western scientific approaches, conversely, prioritize standardized methodologies, replicability, and generalizable principles that transcend specific contexts. The apparent incommensurability between these traditions frequently stems less from fundamental epistemological incompatibility than from different emphasizes regarding what constitutes relevant evidence, appropriate temporal scales of analysis, and legitimate forms of knowledge transmission. Particularly challenging are cases where indigenous knowledge incorporates spiritual or metaphysical dimensions that resist translation into scientific frameworks. However, numerous successful collaborations demonstrate that meaningful integration is possible when both knowledge systems are respected on their own terms. For instance, in Arctic regions, collaborative research incorporating Inuit traditional knowledge alongside climatological data has yielded more comprehensive understanding of complex sea ice dynamics than either approach could achieve independently. Similarly, Australian aboriginal fire management practices, initially dismissed by colonial authorities, are increasingly recognized as sophisticated ecological interventions that maintain biodiversity and reduce catastrophic wildfire risk. The most productive engagements typically involve contextual validation processes that acknowledge different knowledge systems' distinctive strengths while maintaining standards of evidence appropriate to each tradition. This approach requires institutional transformations within scientific communities and policy frameworks to create genuine co-production of knowledge rather than merely extracting indigenous perspectives. Such transformation necessitates addressing power imbalances, ensuring equitable attribution and intellectual property protection, and developing cross-cultural competencies among researchers from both traditions. Beyond practical applications, this engagement offers valuable opportunities to examine the cultural contingency of all knowledge systems, including Western science, potentially enriching both traditions through critical epistemological reflection."
  }
];

// Pour compatibilité
export const ReadingAvanceIELTSFlashcards = readingAvanceIELTSFlashcards;
